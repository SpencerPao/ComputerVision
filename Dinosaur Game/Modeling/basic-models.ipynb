{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddb3fbf3-eb58-4a63-bc58-adccbc6eb32b",
   "metadata": {},
   "source": [
    "# Dino Game model fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de10ea9d-7a20-4b89-a0ec-72766ec977e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Summary\n",
    "* Initial go at dino game\n",
    "* Read-in Spencer's data and do some very minimal pre-processing to make things play nicely with popular ML pacakges like sklearn, keras, and PyTorch\n",
    "* Fit basic Softmax Regression model -- performs WAY better than I expected\n",
    "* Though this nice performance could be super misguiding -- could be a result of the data structure I mentioend above, or the fact that these samples aren't IID (one frame of the game relies on another) so we are inherently violating the assumptions of a LogReg model. For this, I suggest a \"thinning\" type of approach across even more dino-games if we want to learn an actual mapping\n",
    "* Will likely need a lot more data to train a deep-net, especially since LogReg performs so well.\n",
    "\n",
    "### Inputs\n",
    "\n",
    "* Spencer went all-out and sent massive image files in RGB channels (lol) so for now, I will just flatten these, drop that third channel (will mess up scaling of values in matrix though), and train on these vectors.\n",
    "\n",
    "### Outputs\n",
    "\n",
    "* A label prediction for the key to press (or what action the model should take given the pixel values in the image?)\n",
    "\n",
    "### Modeling task\n",
    "* Given an input image $X$, output a label for the action to be taken by the model (jump, duck, nothing)\n",
    "\n",
    "### Evaluation metric\n",
    "* Classification accuracy \n",
    "* Cross-entropy loss for training\n",
    "\n",
    "### Models\n",
    "* Multinomial logistic/Softmax regression\n",
    "* ConvNets (1D and 2D) -- Spencer suggest ResNet, but I have so little knowledge in this field, I kinda of want to do a \"survey\" first\n",
    "* SVM models?\n",
    "\n",
    "### To-do\n",
    "* Data pre-processing to make this task more \"learnable\" is needed. \n",
    "    * Images should be converted to grayscale -- models not learning well\n",
    "    * Perhaps move from predicting the integer value of the key-press and move to a one-hot encoding (I can write a utility function to go back and forth from the two to make the actual dinosaur move)\n",
    "   \n",
    "* More modeling\n",
    "     * Move to Google Collab for ConvNets -- LogReg was painfully slow on my local machine to fit\n",
    "     * Flat try fancy models next!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d65e5134-9a96-4b39-ae95-549873eb26c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from pathlib import Path\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from typing import List\n",
    "import cv2 as cv\n",
    "# Using SMOTE for the over sampling portion.\n",
    "from imblearn.over_sampling import SMOTE\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6673b37-2693-4d1d-b3e3-b00838146a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length Command Keys Shape:  (15673,)\n",
      "Length Screenshot Shape:  (15673, 129600)\n",
      "Screenshot Shape:  (129600,)\n"
     ]
    }
   ],
   "source": [
    "target_address = os.path.join(Path(os.getcwd()).parent,'Window_capture\\\\Data\\\\command_keys.npy')\n",
    "# screenshot_address = os.path.join(Path(os.getcwd()).parent,'Window_capture\\\\Data\\\\screenshots.npy')\n",
    "screenshot_address = os.path.join(Path(os.getcwd()).parent,'Window_capture\\\\Data\\\\screenshots.npy')\n",
    "\n",
    "labels = np.load(target_address)\n",
    "images = np.load(screenshot_address, allow_pickle = True)\n",
    "\n",
    "\n",
    "print(\"Length Command Keys Shape: \",labels.shape)\n",
    "print(\"Length Screenshot Shape: \",images.shape)\n",
    "print(\"Screenshot Shape: \",images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "423d1624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1, 38, 40]), array([12109,  1523,  2041], dtype=int64))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels, return_counts = True) # We see quite a bit of imbalance among the do nothing / jump / duck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a62edb6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False,  True]), array([ 3564, 12109], dtype=int64))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels == -1, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96360d41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# res_list = [i for i, value in enumerate(labels) if value == -1] # Let's get rid of some -1 values.\n",
    "# idx = np.random.choice(res_list, 2000, replace=False) # Randomly choose X number of entries to be deleted specified as -1\n",
    "# images = pd.DataFrame(images) # flatten images then converted to dataframe for easier removal of idx\n",
    "# images = np.array(images.drop(images.index[idx])) # flatten images then converted to dataframe for easier removal of idx\n",
    "# labels = np.delete(labels, idx)\n",
    "# print(images.shape, labels.shape)\n",
    "# print(np.unique(labels, return_counts = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f66de39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19e07868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1, 38, 40]), array([9058, 1162, 1534], dtype=int64))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0af2c104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1, 38, 40]), array([9058, 9058, 9058], dtype=int64))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Oversampling the data\n",
    "smote = SMOTE(random_state = 101)\n",
    "X_train_samp, y_train_samp = smote.fit_resample(X_train, y_train)\n",
    "np.unique(y_train_samp, return_counts = True) # Oversampled Balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f0ba4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\spenc\\anaconda3\\envs\\cv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit LogReg model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_samp,y_train_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8680cbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg accuracy on held-out frames = 0.9025\n"
     ]
    }
   ],
   "source": [
    "y_hat = log_reg.predict(X_test)\n",
    "print(f'LogReg accuracy on held-out frames = {round(accuracy_score(y_test, y_hat),4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "622024aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.94      0.94      0.94      3051\n",
      "          up       0.53      0.53      0.53       361\n",
      "        down       0.96      0.95      0.96       507\n",
      "\n",
      "    accuracy                           0.90      3919\n",
      "   macro avg       0.81      0.81      0.81      3919\n",
      "weighted avg       0.90      0.90      0.90      3919\n",
      "\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_hat, labels=[-1, 38, 40])\n",
    "target_names = ['nothing', 'up', 'down']\n",
    "print(classification_report(y_test, y_hat, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "490c9a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(log_reg, open('Existing_Models/log-reg.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068caa73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfcb4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
