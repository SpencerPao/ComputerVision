{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aaa85b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from pathlib import Path\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from typing import List\n",
    "import cv2 as cv\n",
    "# Using SMOTE for the over sampling portion.\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafe408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_address = os.path.join(Path(os.getcwd()).parent,'Modeling\\\\Existing_Models\\\\xgboost_dino_tuned.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9104bf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(model_address, 'rb'))  # horrible.\n",
    "print(model.get_xgb_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c946605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length Command Keys Shape:  (23123,)\n",
      "Length Screenshot Shape:  (23123, 64800)\n",
      "Screenshot Shape:  (64800,)\n",
      "(array([-1, 38]), array([15758,  7365], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# target_address = os.path.join(Path(os.getcwd()).parent,'Window_capture\\\\Data\\\\command_keys.npy')\n",
    "# screenshot_address = os.path.join(Path(os.getcwd()).parent,'Window_capture\\\\Data\\\\screenshots.npy')\n",
    "target_address = os.path.join(Path(os.getcwd()).parent,'Window_capture\\\\Data\\\\command_keys_retry.npy')\n",
    "screenshot_address = os.path.join(Path(os.getcwd()).parent,'Window_capture\\\\Data\\\\screenshots_retry.npy')\n",
    "\n",
    "labels = np.load(target_address)\n",
    "images = np.load(screenshot_address, allow_pickle = True)\n",
    "# labels=labels[1500:1700]\n",
    "# images=images[1500:1700,]\n",
    "\n",
    "print(\"Length Command Keys Shape: \",labels.shape)\n",
    "print(\"Length Screenshot Shape: \",images.shape)\n",
    "print(\"Screenshot Shape: \",images[0].shape)\n",
    "print(np.unique(labels, return_counts = True))\n",
    "# res_list = [i for i, value in enumerate(labels) if value == 2] # Remove Ducking\n",
    "# idx = np.random.choice(res_list, 4290, replace=False) # Randomly choose X number of entries to be deleted specified as -1\n",
    "# images = pd.DataFrame(images) # flatten images then converted to dataframe for easier removal of idx\n",
    "# images = np.array(images.drop(images.index[idx])) # flatten images then converted to dataframe for easier removal of idx\n",
    "# labels = np.delete(labels, idx)\n",
    "# print(images.shape, labels.shape)\n",
    "# print(np.unique(labels, return_counts = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0bc983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_list = [i for i, value in enumerate(labels) if value == -1] # Let's get rid of some -1 values.\n",
    "# idx = np.random.choice(res_list, 9000, replace=False) # Randomly choose X number of entries to be deleted specified as -1\n",
    "# images = pd.DataFrame(images) # flatten images then converted to dataframe for easier removal of idx\n",
    "# images = np.array(images.drop(images.index[idx])) # flatten images then converted to dataframe for easier removal of idx\n",
    "# labels = np.delete(labels, idx)\n",
    "# print(images.shape, labels.shape)\n",
    "# print(np.unique(labels, return_counts = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4a0e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersample using Tomek Links\n",
    "# from imblearn.under_sampling import TomekLinks\n",
    "# tl = TomekLinks()\n",
    "# images, labels = tl.fit_resample(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1446e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 101)\n",
    "images, labels = smote.fit_resample(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba3a000",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(labels, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fa82b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast -1 to 0, 38 to 1 and 40 to 2\n",
    "labels[labels == -1] = 0\n",
    "labels[labels == 38] = 1\n",
    "labels[labels == 40] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3723bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f7358c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([11809,  5533], dtype=int64))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad29afd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b5db2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest  = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76ad14ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:35:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\teval-logloss:0.68862\ttrain-logloss:0.68858\n",
      "[1]\teval-logloss:0.68421\ttrain-logloss:0.68417\n",
      "[2]\teval-logloss:0.67978\ttrain-logloss:0.67975\n",
      "[3]\teval-logloss:0.67552\ttrain-logloss:0.67549\n",
      "[4]\teval-logloss:0.67124\ttrain-logloss:0.67126\n",
      "[5]\teval-logloss:0.66710\ttrain-logloss:0.66711\n",
      "[6]\teval-logloss:0.66308\ttrain-logloss:0.66309\n",
      "[7]\teval-logloss:0.65914\ttrain-logloss:0.65911\n",
      "[8]\teval-logloss:0.65524\ttrain-logloss:0.65522\n",
      "[9]\teval-logloss:0.65138\ttrain-logloss:0.65136\n",
      "[10]\teval-logloss:0.64764\ttrain-logloss:0.64758\n",
      "[11]\teval-logloss:0.64394\ttrain-logloss:0.64386\n",
      "[12]\teval-logloss:0.64029\ttrain-logloss:0.64022\n",
      "[13]\teval-logloss:0.63670\ttrain-logloss:0.63663\n",
      "[14]\teval-logloss:0.63316\ttrain-logloss:0.63311\n",
      "[15]\teval-logloss:0.62972\ttrain-logloss:0.62969\n",
      "[16]\teval-logloss:0.62633\ttrain-logloss:0.62631\n",
      "[17]\teval-logloss:0.62298\ttrain-logloss:0.62298\n",
      "[18]\teval-logloss:0.61977\ttrain-logloss:0.61977\n",
      "[19]\teval-logloss:0.61654\ttrain-logloss:0.61652\n",
      "[20]\teval-logloss:0.61341\ttrain-logloss:0.61336\n",
      "[21]\teval-logloss:0.61034\ttrain-logloss:0.61029\n",
      "[22]\teval-logloss:0.60728\ttrain-logloss:0.60723\n",
      "[23]\teval-logloss:0.60427\ttrain-logloss:0.60422\n",
      "[24]\teval-logloss:0.60132\ttrain-logloss:0.60126\n",
      "[25]\teval-logloss:0.59842\ttrain-logloss:0.59832\n",
      "[26]\teval-logloss:0.59557\ttrain-logloss:0.59545\n",
      "[27]\teval-logloss:0.59276\ttrain-logloss:0.59264\n",
      "[28]\teval-logloss:0.58996\ttrain-logloss:0.58987\n",
      "[29]\teval-logloss:0.58721\ttrain-logloss:0.58710\n",
      "[30]\teval-logloss:0.58449\ttrain-logloss:0.58440\n",
      "[31]\teval-logloss:0.58186\ttrain-logloss:0.58178\n",
      "[32]\teval-logloss:0.57927\ttrain-logloss:0.57916\n",
      "[33]\teval-logloss:0.57672\ttrain-logloss:0.57659\n",
      "[34]\teval-logloss:0.57420\ttrain-logloss:0.57407\n",
      "[35]\teval-logloss:0.57174\ttrain-logloss:0.57158\n",
      "[36]\teval-logloss:0.56927\ttrain-logloss:0.56912\n",
      "[37]\teval-logloss:0.56685\ttrain-logloss:0.56671\n",
      "[38]\teval-logloss:0.56450\ttrain-logloss:0.56434\n",
      "[39]\teval-logloss:0.56217\ttrain-logloss:0.56201\n",
      "[40]\teval-logloss:0.55989\ttrain-logloss:0.55972\n",
      "[41]\teval-logloss:0.55763\ttrain-logloss:0.55745\n",
      "[42]\teval-logloss:0.55541\ttrain-logloss:0.55524\n",
      "[43]\teval-logloss:0.55323\ttrain-logloss:0.55305\n",
      "[44]\teval-logloss:0.55114\ttrain-logloss:0.55093\n",
      "[45]\teval-logloss:0.54900\ttrain-logloss:0.54880\n",
      "[46]\teval-logloss:0.54697\ttrain-logloss:0.54672\n",
      "[47]\teval-logloss:0.54499\ttrain-logloss:0.54469\n",
      "[48]\teval-logloss:0.54300\ttrain-logloss:0.54266\n",
      "[49]\teval-logloss:0.54100\ttrain-logloss:0.54066\n",
      "[50]\teval-logloss:0.53902\ttrain-logloss:0.53869\n",
      "[51]\teval-logloss:0.53706\ttrain-logloss:0.53673\n",
      "[52]\teval-logloss:0.53514\ttrain-logloss:0.53481\n",
      "[53]\teval-logloss:0.53329\ttrain-logloss:0.53295\n",
      "[54]\teval-logloss:0.53141\ttrain-logloss:0.53107\n",
      "[55]\teval-logloss:0.52958\ttrain-logloss:0.52924\n",
      "[56]\teval-logloss:0.52781\ttrain-logloss:0.52743\n",
      "[57]\teval-logloss:0.52603\ttrain-logloss:0.52565\n",
      "[58]\teval-logloss:0.52428\ttrain-logloss:0.52390\n",
      "[59]\teval-logloss:0.52253\ttrain-logloss:0.52215\n",
      "[60]\teval-logloss:0.52085\ttrain-logloss:0.52046\n",
      "[61]\teval-logloss:0.51918\ttrain-logloss:0.51878\n",
      "[62]\teval-logloss:0.51750\ttrain-logloss:0.51711\n",
      "[63]\teval-logloss:0.51587\ttrain-logloss:0.51546\n",
      "[64]\teval-logloss:0.51426\ttrain-logloss:0.51384\n",
      "[65]\teval-logloss:0.51268\ttrain-logloss:0.51225\n",
      "[66]\teval-logloss:0.51112\ttrain-logloss:0.51068\n",
      "[67]\teval-logloss:0.50957\ttrain-logloss:0.50911\n",
      "[68]\teval-logloss:0.50803\ttrain-logloss:0.50755\n",
      "[69]\teval-logloss:0.50654\ttrain-logloss:0.50606\n",
      "[70]\teval-logloss:0.50508\ttrain-logloss:0.50459\n",
      "[71]\teval-logloss:0.50361\ttrain-logloss:0.50312\n",
      "[72]\teval-logloss:0.50217\ttrain-logloss:0.50168\n",
      "[73]\teval-logloss:0.50078\ttrain-logloss:0.50027\n",
      "[74]\teval-logloss:0.49938\ttrain-logloss:0.49885\n",
      "[75]\teval-logloss:0.49798\ttrain-logloss:0.49744\n",
      "[76]\teval-logloss:0.49662\ttrain-logloss:0.49608\n",
      "[77]\teval-logloss:0.49529\ttrain-logloss:0.49474\n",
      "[78]\teval-logloss:0.49397\ttrain-logloss:0.49340\n",
      "[79]\teval-logloss:0.49265\ttrain-logloss:0.49209\n",
      "[80]\teval-logloss:0.49138\ttrain-logloss:0.49080\n",
      "[81]\teval-logloss:0.49012\ttrain-logloss:0.48954\n",
      "[82]\teval-logloss:0.48889\ttrain-logloss:0.48828\n",
      "[83]\teval-logloss:0.48766\ttrain-logloss:0.48703\n",
      "[84]\teval-logloss:0.48644\ttrain-logloss:0.48583\n",
      "[85]\teval-logloss:0.48525\ttrain-logloss:0.48463\n",
      "[86]\teval-logloss:0.48408\ttrain-logloss:0.48345\n",
      "[87]\teval-logloss:0.48295\ttrain-logloss:0.48227\n",
      "[88]\teval-logloss:0.48180\ttrain-logloss:0.48111\n",
      "[89]\teval-logloss:0.48067\ttrain-logloss:0.47995\n",
      "[90]\teval-logloss:0.47959\ttrain-logloss:0.47885\n",
      "[91]\teval-logloss:0.47849\ttrain-logloss:0.47774\n",
      "[92]\teval-logloss:0.47743\ttrain-logloss:0.47666\n",
      "[93]\teval-logloss:0.47637\ttrain-logloss:0.47559\n",
      "[94]\teval-logloss:0.47532\ttrain-logloss:0.47452\n",
      "[95]\teval-logloss:0.47427\ttrain-logloss:0.47345\n",
      "[96]\teval-logloss:0.47323\ttrain-logloss:0.47241\n",
      "[97]\teval-logloss:0.47222\ttrain-logloss:0.47139\n",
      "[98]\teval-logloss:0.47122\ttrain-logloss:0.47037\n",
      "[99]\teval-logloss:0.47026\ttrain-logloss:0.46939\n",
      "[100]\teval-logloss:0.46931\ttrain-logloss:0.46841\n",
      "[101]\teval-logloss:0.46836\ttrain-logloss:0.46746\n",
      "[102]\teval-logloss:0.46740\ttrain-logloss:0.46649\n",
      "[103]\teval-logloss:0.46647\ttrain-logloss:0.46554\n",
      "[104]\teval-logloss:0.46557\ttrain-logloss:0.46460\n",
      "[105]\teval-logloss:0.46465\ttrain-logloss:0.46365\n",
      "[106]\teval-logloss:0.46375\ttrain-logloss:0.46274\n",
      "[107]\teval-logloss:0.46287\ttrain-logloss:0.46186\n",
      "[108]\teval-logloss:0.46199\ttrain-logloss:0.46095\n",
      "[109]\teval-logloss:0.46114\ttrain-logloss:0.46009\n",
      "[110]\teval-logloss:0.46028\ttrain-logloss:0.45924\n",
      "[111]\teval-logloss:0.45943\ttrain-logloss:0.45837\n",
      "[112]\teval-logloss:0.45857\ttrain-logloss:0.45750\n",
      "[113]\teval-logloss:0.45776\ttrain-logloss:0.45667\n",
      "[114]\teval-logloss:0.45695\ttrain-logloss:0.45585\n",
      "[115]\teval-logloss:0.45615\ttrain-logloss:0.45504\n",
      "[116]\teval-logloss:0.45535\ttrain-logloss:0.45423\n",
      "[117]\teval-logloss:0.45455\ttrain-logloss:0.45341\n",
      "[118]\teval-logloss:0.45377\ttrain-logloss:0.45263\n",
      "[119]\teval-logloss:0.45303\ttrain-logloss:0.45185\n",
      "[120]\teval-logloss:0.45228\ttrain-logloss:0.45109\n",
      "[121]\teval-logloss:0.45158\ttrain-logloss:0.45033\n",
      "[122]\teval-logloss:0.45084\ttrain-logloss:0.44960\n",
      "[123]\teval-logloss:0.45011\ttrain-logloss:0.44885\n",
      "[124]\teval-logloss:0.44942\ttrain-logloss:0.44813\n",
      "[125]\teval-logloss:0.44870\ttrain-logloss:0.44739\n",
      "[126]\teval-logloss:0.44800\ttrain-logloss:0.44669\n",
      "[127]\teval-logloss:0.44730\ttrain-logloss:0.44597\n",
      "[128]\teval-logloss:0.44664\ttrain-logloss:0.44528\n",
      "[129]\teval-logloss:0.44595\ttrain-logloss:0.44459\n",
      "[130]\teval-logloss:0.44527\ttrain-logloss:0.44391\n",
      "[131]\teval-logloss:0.44463\ttrain-logloss:0.44324\n",
      "[132]\teval-logloss:0.44397\ttrain-logloss:0.44258\n",
      "[133]\teval-logloss:0.44333\ttrain-logloss:0.44193\n",
      "[134]\teval-logloss:0.44268\ttrain-logloss:0.44127\n",
      "[135]\teval-logloss:0.44206\ttrain-logloss:0.44064\n",
      "[136]\teval-logloss:0.44147\ttrain-logloss:0.44002\n",
      "[137]\teval-logloss:0.44088\ttrain-logloss:0.43940\n",
      "[138]\teval-logloss:0.44027\ttrain-logloss:0.43878\n",
      "[139]\teval-logloss:0.43966\ttrain-logloss:0.43816\n",
      "[140]\teval-logloss:0.43911\ttrain-logloss:0.43756\n",
      "[141]\teval-logloss:0.43854\ttrain-logloss:0.43696\n",
      "[142]\teval-logloss:0.43795\ttrain-logloss:0.43636\n",
      "[143]\teval-logloss:0.43741\ttrain-logloss:0.43580\n",
      "[144]\teval-logloss:0.43684\ttrain-logloss:0.43521\n",
      "[145]\teval-logloss:0.43631\ttrain-logloss:0.43465\n",
      "[146]\teval-logloss:0.43574\ttrain-logloss:0.43408\n",
      "[147]\teval-logloss:0.43520\ttrain-logloss:0.43353\n",
      "[148]\teval-logloss:0.43467\ttrain-logloss:0.43297\n",
      "[149]\teval-logloss:0.43418\ttrain-logloss:0.43244\n",
      "[150]\teval-logloss:0.43366\ttrain-logloss:0.43189\n",
      "[151]\teval-logloss:0.43315\ttrain-logloss:0.43137\n",
      "[152]\teval-logloss:0.43265\ttrain-logloss:0.43085\n",
      "[153]\teval-logloss:0.43217\ttrain-logloss:0.43033\n",
      "[154]\teval-logloss:0.43168\ttrain-logloss:0.42982\n",
      "[155]\teval-logloss:0.43119\ttrain-logloss:0.42932\n",
      "[156]\teval-logloss:0.43073\ttrain-logloss:0.42882\n",
      "[157]\teval-logloss:0.43027\ttrain-logloss:0.42832\n",
      "[158]\teval-logloss:0.42984\ttrain-logloss:0.42783\n",
      "[159]\teval-logloss:0.42938\ttrain-logloss:0.42735\n",
      "[160]\teval-logloss:0.42892\ttrain-logloss:0.42687\n",
      "[161]\teval-logloss:0.42845\ttrain-logloss:0.42640\n",
      "[162]\teval-logloss:0.42801\ttrain-logloss:0.42592\n",
      "[163]\teval-logloss:0.42755\ttrain-logloss:0.42545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[164]\teval-logloss:0.42712\ttrain-logloss:0.42498\n",
      "[165]\teval-logloss:0.42669\ttrain-logloss:0.42453\n",
      "[166]\teval-logloss:0.42627\ttrain-logloss:0.42409\n",
      "[167]\teval-logloss:0.42586\ttrain-logloss:0.42365\n",
      "[168]\teval-logloss:0.42546\ttrain-logloss:0.42321\n",
      "[169]\teval-logloss:0.42506\ttrain-logloss:0.42278\n",
      "[170]\teval-logloss:0.42463\ttrain-logloss:0.42235\n",
      "[171]\teval-logloss:0.42423\ttrain-logloss:0.42193\n",
      "[172]\teval-logloss:0.42384\ttrain-logloss:0.42151\n",
      "[173]\teval-logloss:0.42345\ttrain-logloss:0.42110\n",
      "[174]\teval-logloss:0.42307\ttrain-logloss:0.42068\n",
      "[175]\teval-logloss:0.42269\ttrain-logloss:0.42029\n",
      "[176]\teval-logloss:0.42231\ttrain-logloss:0.41988\n",
      "[177]\teval-logloss:0.42192\ttrain-logloss:0.41948\n",
      "[178]\teval-logloss:0.42155\ttrain-logloss:0.41909\n",
      "[179]\teval-logloss:0.42119\ttrain-logloss:0.41870\n",
      "[180]\teval-logloss:0.42084\ttrain-logloss:0.41830\n",
      "[181]\teval-logloss:0.42048\ttrain-logloss:0.41793\n",
      "[182]\teval-logloss:0.42012\ttrain-logloss:0.41757\n",
      "[183]\teval-logloss:0.41978\ttrain-logloss:0.41720\n",
      "[184]\teval-logloss:0.41944\ttrain-logloss:0.41684\n",
      "[185]\teval-logloss:0.41908\ttrain-logloss:0.41648\n",
      "[186]\teval-logloss:0.41874\ttrain-logloss:0.41611\n",
      "[187]\teval-logloss:0.41844\ttrain-logloss:0.41574\n",
      "[188]\teval-logloss:0.41811\ttrain-logloss:0.41541\n",
      "[189]\teval-logloss:0.41779\ttrain-logloss:0.41505\n",
      "[190]\teval-logloss:0.41748\ttrain-logloss:0.41471\n",
      "[191]\teval-logloss:0.41717\ttrain-logloss:0.41438\n",
      "[192]\teval-logloss:0.41685\ttrain-logloss:0.41403\n",
      "[193]\teval-logloss:0.41653\ttrain-logloss:0.41370\n",
      "[194]\teval-logloss:0.41622\ttrain-logloss:0.41337\n",
      "[195]\teval-logloss:0.41592\ttrain-logloss:0.41304\n",
      "[196]\teval-logloss:0.41564\ttrain-logloss:0.41271\n",
      "[197]\teval-logloss:0.41534\ttrain-logloss:0.41240\n",
      "[198]\teval-logloss:0.41504\ttrain-logloss:0.41207\n",
      "[199]\teval-logloss:0.41478\ttrain-logloss:0.41176\n",
      "[200]\teval-logloss:0.41450\ttrain-logloss:0.41145\n",
      "[201]\teval-logloss:0.41421\ttrain-logloss:0.41115\n",
      "[202]\teval-logloss:0.41395\ttrain-logloss:0.41084\n",
      "[203]\teval-logloss:0.41368\ttrain-logloss:0.41055\n",
      "[204]\teval-logloss:0.41340\ttrain-logloss:0.41024\n",
      "[205]\teval-logloss:0.41315\ttrain-logloss:0.40993\n",
      "[206]\teval-logloss:0.41290\ttrain-logloss:0.40964\n",
      "[207]\teval-logloss:0.41263\ttrain-logloss:0.40936\n",
      "[208]\teval-logloss:0.41236\ttrain-logloss:0.40908\n",
      "[209]\teval-logloss:0.41209\ttrain-logloss:0.40879\n",
      "[210]\teval-logloss:0.41184\ttrain-logloss:0.40851\n",
      "[211]\teval-logloss:0.41158\ttrain-logloss:0.40822\n",
      "[212]\teval-logloss:0.41132\ttrain-logloss:0.40795\n",
      "[213]\teval-logloss:0.41107\ttrain-logloss:0.40769\n",
      "[214]\teval-logloss:0.41084\ttrain-logloss:0.40742\n",
      "[215]\teval-logloss:0.41059\ttrain-logloss:0.40715\n",
      "[216]\teval-logloss:0.41035\ttrain-logloss:0.40688\n",
      "[217]\teval-logloss:0.41012\ttrain-logloss:0.40661\n",
      "[218]\teval-logloss:0.40989\ttrain-logloss:0.40635\n",
      "[219]\teval-logloss:0.40967\ttrain-logloss:0.40609\n",
      "[220]\teval-logloss:0.40945\ttrain-logloss:0.40583\n",
      "[221]\teval-logloss:0.40923\ttrain-logloss:0.40559\n",
      "[222]\teval-logloss:0.40901\ttrain-logloss:0.40533\n",
      "[223]\teval-logloss:0.40879\ttrain-logloss:0.40508\n",
      "[224]\teval-logloss:0.40856\ttrain-logloss:0.40485\n",
      "[225]\teval-logloss:0.40835\ttrain-logloss:0.40459\n",
      "[226]\teval-logloss:0.40816\ttrain-logloss:0.40436\n",
      "[227]\teval-logloss:0.40796\ttrain-logloss:0.40410\n",
      "[228]\teval-logloss:0.40775\ttrain-logloss:0.40387\n",
      "[229]\teval-logloss:0.40756\ttrain-logloss:0.40362\n",
      "[230]\teval-logloss:0.40736\ttrain-logloss:0.40340\n",
      "[231]\teval-logloss:0.40715\ttrain-logloss:0.40316\n",
      "[232]\teval-logloss:0.40697\ttrain-logloss:0.40293\n",
      "[233]\teval-logloss:0.40679\ttrain-logloss:0.40272\n",
      "[234]\teval-logloss:0.40662\ttrain-logloss:0.40246\n",
      "[235]\teval-logloss:0.40644\ttrain-logloss:0.40224\n",
      "[236]\teval-logloss:0.40627\ttrain-logloss:0.40202\n",
      "[237]\teval-logloss:0.40609\ttrain-logloss:0.40179\n",
      "[238]\teval-logloss:0.40591\ttrain-logloss:0.40158\n",
      "[239]\teval-logloss:0.40574\ttrain-logloss:0.40135\n",
      "[240]\teval-logloss:0.40558\ttrain-logloss:0.40113\n",
      "[241]\teval-logloss:0.40540\ttrain-logloss:0.40091\n",
      "[242]\teval-logloss:0.40523\ttrain-logloss:0.40070\n",
      "[243]\teval-logloss:0.40504\ttrain-logloss:0.40049\n",
      "[244]\teval-logloss:0.40488\ttrain-logloss:0.40029\n",
      "[245]\teval-logloss:0.40475\ttrain-logloss:0.40006\n",
      "[246]\teval-logloss:0.40459\ttrain-logloss:0.39985\n",
      "[247]\teval-logloss:0.40443\ttrain-logloss:0.39965\n",
      "[248]\teval-logloss:0.40427\ttrain-logloss:0.39946\n",
      "[249]\teval-logloss:0.40413\ttrain-logloss:0.39925\n",
      "[250]\teval-logloss:0.40397\ttrain-logloss:0.39906\n",
      "[251]\teval-logloss:0.40380\ttrain-logloss:0.39887\n",
      "[252]\teval-logloss:0.40365\ttrain-logloss:0.39868\n",
      "[253]\teval-logloss:0.40349\ttrain-logloss:0.39848\n",
      "[254]\teval-logloss:0.40336\ttrain-logloss:0.39829\n",
      "[255]\teval-logloss:0.40322\ttrain-logloss:0.39811\n",
      "[256]\teval-logloss:0.40308\ttrain-logloss:0.39794\n",
      "[257]\teval-logloss:0.40293\ttrain-logloss:0.39777\n",
      "[258]\teval-logloss:0.40278\ttrain-logloss:0.39758\n",
      "[259]\teval-logloss:0.40263\ttrain-logloss:0.39739\n",
      "[260]\teval-logloss:0.40249\ttrain-logloss:0.39720\n",
      "[261]\teval-logloss:0.40236\ttrain-logloss:0.39704\n",
      "[262]\teval-logloss:0.40220\ttrain-logloss:0.39686\n",
      "[263]\teval-logloss:0.40206\ttrain-logloss:0.39669\n",
      "[264]\teval-logloss:0.40192\ttrain-logloss:0.39652\n",
      "[265]\teval-logloss:0.40178\ttrain-logloss:0.39635\n",
      "[266]\teval-logloss:0.40167\ttrain-logloss:0.39616\n",
      "[267]\teval-logloss:0.40154\ttrain-logloss:0.39599\n",
      "[268]\teval-logloss:0.40141\ttrain-logloss:0.39583\n",
      "[269]\teval-logloss:0.40126\ttrain-logloss:0.39567\n",
      "[270]\teval-logloss:0.40114\ttrain-logloss:0.39550\n",
      "[271]\teval-logloss:0.40100\ttrain-logloss:0.39534\n",
      "[272]\teval-logloss:0.40088\ttrain-logloss:0.39518\n",
      "[273]\teval-logloss:0.40075\ttrain-logloss:0.39503\n",
      "[274]\teval-logloss:0.40061\ttrain-logloss:0.39487\n",
      "[275]\teval-logloss:0.40050\ttrain-logloss:0.39470\n",
      "[276]\teval-logloss:0.40038\ttrain-logloss:0.39454\n",
      "[277]\teval-logloss:0.40028\ttrain-logloss:0.39437\n",
      "[278]\teval-logloss:0.40016\ttrain-logloss:0.39421\n",
      "[279]\teval-logloss:0.40004\ttrain-logloss:0.39406\n",
      "[280]\teval-logloss:0.39993\ttrain-logloss:0.39391\n",
      "[281]\teval-logloss:0.39981\ttrain-logloss:0.39376\n",
      "[282]\teval-logloss:0.39970\ttrain-logloss:0.39361\n",
      "[283]\teval-logloss:0.39959\ttrain-logloss:0.39345\n",
      "[284]\teval-logloss:0.39949\ttrain-logloss:0.39330\n",
      "[285]\teval-logloss:0.39937\ttrain-logloss:0.39315\n",
      "[286]\teval-logloss:0.39928\ttrain-logloss:0.39299\n",
      "[287]\teval-logloss:0.39916\ttrain-logloss:0.39285\n",
      "[288]\teval-logloss:0.39905\ttrain-logloss:0.39272\n",
      "[289]\teval-logloss:0.39895\ttrain-logloss:0.39255\n",
      "[290]\teval-logloss:0.39885\ttrain-logloss:0.39242\n",
      "[291]\teval-logloss:0.39874\ttrain-logloss:0.39228\n",
      "[292]\teval-logloss:0.39864\ttrain-logloss:0.39213\n",
      "[293]\teval-logloss:0.39854\ttrain-logloss:0.39200\n",
      "[294]\teval-logloss:0.39846\ttrain-logloss:0.39187\n",
      "[295]\teval-logloss:0.39836\ttrain-logloss:0.39170\n",
      "[296]\teval-logloss:0.39825\ttrain-logloss:0.39155\n",
      "[297]\teval-logloss:0.39818\ttrain-logloss:0.39140\n",
      "[298]\teval-logloss:0.39808\ttrain-logloss:0.39127\n",
      "[299]\teval-logloss:0.39798\ttrain-logloss:0.39114\n",
      "XGBoost (no wrapper) Time: 1650.2554459571838s\n"
     ]
    }
   ],
   "source": [
    "# Convert the data to DMatrix for xgboost\n",
    "\n",
    "# Loop through multiple thread numbers for xgboost\n",
    "start_time = time.time()\n",
    "# n_estimators = 100\n",
    "# param = {\n",
    "#           'max_depth' : 7,\n",
    "#                 'eta' : 0.1,\n",
    "#     'min_child_weight': 3,\n",
    "#     'colsample_bytree': 0.7,\n",
    "#             'subsample': 0.8,\n",
    "#            'objective':'multi:softmax',\n",
    "#            'num_class': 3,\n",
    "#         }\n",
    "\n",
    "n_estimators = 300\n",
    "param = {\n",
    "          'max_depth' : 9,\n",
    "                'eta' : 0.01,\n",
    "    'min_child_weight': 4,\n",
    "    'colsample_bytree': 0.8,\n",
    "            'subsample': 0.7,\n",
    "           'objective':'binary:logistic',\n",
    "#            'num_class': 2,\n",
    "        }\n",
    "\n",
    "\n",
    "bst = xgb.train(param,\n",
    "                dtrain,\n",
    "                n_estimators,\n",
    "                [(dtest, 'eval'), (dtrain, 'train')],\n",
    "               early_stopping_rounds = 50)\n",
    "print(\"XGBoost (no wrapper) Time: {}s\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47472146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.8194084068500259\n",
      "Prediction time --- 1650.6954455375671 seconds ---\n"
     ]
    }
   ],
   "source": [
    "preds = np.round(bst.predict(dtest) )\n",
    "acc = 1. - (np.abs(preds - y_test).sum() / y_test.shape[0])\n",
    "print(\"Acc: {}\".format(acc))\n",
    "print(\"Prediction time --- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaf171f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29796073, 0.30754814, 0.05016711, ..., 0.33162966, 0.02563015,\n",
       "       0.31021076], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bf9a63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg accuracy on held-out frames = 0.8194\n"
     ]
    }
   ],
   "source": [
    "# make predictions for test data\n",
    "y_hat = np.round(bst.predict(dtest))\n",
    "print(f'LogReg accuracy on held-out frames = {round(accuracy_score(y_test, y_hat),4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c197852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.79      0.99      0.88      3949\n",
      "          up       0.97      0.44      0.61      1832\n",
      "\n",
      "    accuracy                           0.82      5781\n",
      "   macro avg       0.88      0.72      0.75      5781\n",
      "weighted avg       0.85      0.82      0.80      5781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# confusion_matrix(y_test, y_hat, labels=[0, 1, 2])\n",
    "# target_names = ['nothing', 'up', 'down']\n",
    "confusion_matrix(y_test, y_hat, labels=[0, 1])\n",
    "target_names = ['nothing', 'up']\n",
    "print(classification_report(y_test, y_hat, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "577cebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(bst, open('Existing_Models/xgb_retry_03.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee0f4ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9be50b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86e8c68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
